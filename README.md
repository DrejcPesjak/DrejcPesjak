
# Today's AI News

![Todays Image](pictures/20241229_101140.png)

## AI Reddit Recap:

**DeepSeek's Cost-Effective AI:**

- DeepSeek's new model, DeepSeek-V3, significantly outperforms GPT-4o at 10% the cost.
- Concerns arise over privacy and performance, but its affordable price ($5.5 million) and open-sourced paper garner praise.


**DeepSeek's 671 Billion Parameter MoE:**

- DeepSeek researchers showcased the training of a 671 billion parameter Mixture-of-Experts (MoE) model.
- The efficient architecture and parallel training lead to a cost of only $8-10 million.


**OpenAI's Financial Challenges:**

- OpenAI admits needing more capital than expected.
- Discussions around its fundraising plans and potential for-profit strategies are ongoing.


**ChatGPT's Playful Conversation:**

- A lighthearted post features an interaction with ChatGPT where the AI playfully responds to inquiries and displays an understanding of humor.
- The exchange highlights the conversational capabilities of LLMs and their potential for engaging interactions.


**AI and Mathematics: Perspective and Limits:**

- A discussion analyzes the limitations of current AI technology in performing mathematical tasks.
- Concerns arise over misleading descriptions of AI performance in competitions and the need for nuanced understanding of their capabilities.
